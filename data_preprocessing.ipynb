{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "This is a mini tutorial of data preprocessing using scikit-learn package, topics here we going to discuss are:\n",
    "-  Mean removal\n",
    "-  Min Max Scaling\n",
    "-  Normalization\n",
    "-  Binarization\n",
    "-  One hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization or Mean Removal:\n",
    "\n",
    "Standardization of data is a compulsory for most of the machine learning models implemented using scikit-learn. To avoid bad behaviours of our data we need to standardize them to zero mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.22474487,  0.70710678, -0.26726124],\n",
       "       [ 0.        , -1.41421356,  1.33630621],\n",
       "       [-1.22474487,  0.70710678, -1.06904497]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "X_train = np.array([[2.,  1.,  0.],\n",
    "                    [1., -1.,  2.],\n",
    "                    [0.,  1., -1.]])\n",
    "\n",
    "# Lets use the scale function for getting zero mean and unit variance\n",
    "X_scaled = preprocessing.scale(X_train)\n",
    "\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Lets check the mean and variance:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.00000000e+00,   7.40148683e-17,   0.00000000e+00])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min Max Scaling:\n",
    "\n",
    "This is an alternative standardization technique which is for scaling features to lie between a given range(often between zero and one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5       ,  0.        ,  1.        ],\n",
       "       [ 1.        ,  0.5       ,  0.33333333],\n",
       "       [ 0.        ,  1.        ,  0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample data matrix\n",
    "X_train = np.array([[1., -1.,  2.],\n",
    "                    [2.,  0.,  0.],\n",
    "                    [0.,  1., -1.]])\n",
    "\n",
    "# Scaling a data matrix to the [0, 1] range\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
    "\n",
    "X_train_minmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization:\n",
    "\n",
    "This process invloves scaling individual samples to have unit norm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25, -0.25,  0.5 ],\n",
       "       [ 1.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.5 , -0.5 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample data\n",
    "X = [[1., -1.,  2.],\n",
    "     [2.,  0.,  0.],\n",
    "     [0.,  1., -1.]]\n",
    "\n",
    "# Lets normalize the data using norms l1 or l2\n",
    "X_normalized = preprocessing.normalize(X, norm='l1')\n",
    "\n",
    "X_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarization:\n",
    "\n",
    "Binarization is the process of thresholding numerical features to get boolean values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[1., -1.,  2.],\n",
    "     [2.,  0.,  0.],\n",
    "     [0.,  1., -1.]]\n",
    "\n",
    "binarizer = preprocessing.Binarizer(threshold=1.1)\n",
    "\n",
    "binarizer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding:\n",
    "\n",
    "This is used to convert categorical features into binary features. This estimator transforms each categorical feature with m possible values into m binary features, with only one active. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender = ['male', 'female']  # [0, 1]\n",
    "continent = ['from Europe', 'from US', 'from Asia']  # [0, 1, 2]\n",
    "browser = ['uses Firefox',\n",
    "           'uses Chrome',\n",
    "           'uses Safari', \n",
    "           'uses Internet Explorer']  # [0, 1, 2, 3]\n",
    "\n",
    "sample_data = ['male', 'from US', 'uses Internet Explorer']  # [0, 1, 3]\n",
    "\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]])\n",
    "enc.transform([[0, 1, 3]]).toarray()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
